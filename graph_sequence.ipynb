{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35828e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5653312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = pd.read_excel(\"candidate_master_data.xlsx\",sheet_name='Candidate Data')\n",
    "candidate.to_csv(\"candidate_master.csv\",index=None,header=True)\n",
    "cand_d = pd.read_csv(\"candidate_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984dae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_parsing(skill):\n",
    "    '''\n",
    "    Function that extracts the skills from the Skill column and creates seperate primary and secondary skillsets with experience\n",
    "    in each skill. This will be later appended to the main table dropping the main Skill column.\n",
    "    '''\n",
    "    res = json.loads(skill,strict=False)\n",
    "    skill_list=res['skills']\n",
    "    \n",
    "    primary_skill = {}\n",
    "    secondary_skill = {}\n",
    "\n",
    "    for i in range (len(skill_list)):\n",
    "        if skill_list[i]['skill_type'] == 'primary':\n",
    "            primary_skill[skill_list[i]['skill']]=skill_list[i]['total_exp_in_each_skill']\n",
    "        else:\n",
    "            if skill_list[i]['skill_type'] == 'secondary':\n",
    "                secondary_skill[skill_list[i]['skill']]=skill_list[i]['total_exp_in_each_skill']\n",
    "    return primary_skill, secondary_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564ea368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import more_itertools\n",
    "import json\n",
    "from neo4j import GraphDatabase, Driver\n",
    "\n",
    "class GraphSequence(tf.keras.utils.Sequence):\n",
    "\n",
    "\tdef __init__(self, args, batch_size=32, test=False):\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\t\n",
    "\t\tself.query = \"\"\"\n",
    "\t\t\tMATCH \n",
    "            \n",
    "\t\t\tRETURN as x, score as y\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tself.query_params = {\n",
    "\t\t\t\"dataset_name\": \"article_0\",\n",
    "\t\t\t\"test\": test\n",
    "\t\t}\n",
    "\n",
    "\t\twith open('./settings.json') as f:\n",
    "\t\t\tself.settings = json.load(f)[args.database]\n",
    "\n",
    "\t\tdriver = GraphDatabase.driver(\n",
    "\t\t\tself.settings[\"neo4j_url\"], \n",
    "\t\t\tauth=(self.settings[\"neo4j_user\"], self.settings[\"neo4j_password\"]))\n",
    "\n",
    "\t\twith driver.session() as session:\n",
    "\t\t\tdata = session.run(self.query, **self.query_params).data()\n",
    "\t\t\tdata = [ (np.array(i[\"x\"]), i[\"y\"]) for i in data]\n",
    "\t\t\t\n",
    "\t\t\t# Split the data up into \"batches\"\n",
    "\t\t\tdata = more_itertools.chunked(data, self.batch_size)\n",
    "\n",
    "\t\t\t# Format our batches in the way Keras expects them:\n",
    "\t\t\t# An array of tuples (x_batch, y_batch)\n",
    "\n",
    "\t\t\t# An x_batch is a numpy array of shape (batch_size, 12), \n",
    "\t\t\t# containing the concatenated style and style_preference vectors. \n",
    "\n",
    "\t\t\t# A y_batch is a numpy array of shape (batch_size,1) containing the review scores.\n",
    "\n",
    "\t\t\tself.data = [ (np.array([j[0] for j in i]), np.array([j[1] for j in i])) for i in data]\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\treturn self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186527f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
